<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Preprocessing</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/prism.css" />
	</head>
	<body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="index.html">Home</a></li>
					<li><a href="#top">Data Preprocessing</a></li>
					<li><a href="visualization.html">Data Visualization</a></li>
					<li><a href="data_modeling.html">Data Modeling</a></li>
				</ul>
			</nav>

			<!-- Header -->
			<article class="wrapper style1 compact">
				<header>
					<h2>Data Preprocessing</h2>
					<p>This section details how the team preprocessed the data gathered during the <b>data collection</b> phase.</p>
				</header>
				<div class="col-12">
					<section class="box style3 compact desc">
						<h3>Outline</h3>
							<ol class="outline" style="list-style-type:upper-roman">
								<li><a href="#missing-values">Handling missing values</a></li>
								<li><a href="#format-consistency">Format Consistency</a></li>
								<li>
									Handling Outliers
									<ol style="list-style-type:upper-alpha">
										<li><a href="#examine-distribution">Examining the Distribution</a></li>
										<li><a href="#detecting-outliers">Detecting Outliers</a></li>
										<li><a href="#imputing-outliers">Imputing the Outliers</a></li>
									</ol>
								</li>
								<li><a href="#normalization">Normalization</a></li>
								<li><a href="#categorical-encoding">Categorical Data Encoding</a></li>
								<li>
									Natural Language Processing
									<ol style="list-style-type:upper-alpha">
										<li><a href="#cleaning-setup">Cleaning and Setup</a></li>
										<li><a href="#token-stopwords">Tokenization and Stopwords</a></li>
										<li><a href="#lemmatization">Lemmatization</a></li>
									</ol>
								</li>
							</ol>
					</section>
				</div>
			</article>
		
			<!-- Content -->
			<article class="wrapper style2 compact">
				<div class="container">
					<div class="row aln-center">
						<div id="missing-values" class="col-12">
							<section class="box style4 desc">
								<h3>Handling missing values</h3>
									The stark majority of preprocessing was performed using Deepnote as the collaboration platform. <br>
									The first step involves cleaning up the raw data which contained columns unnecessary for
									data analyses.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	import pandas as pd

	path = "Dataset - Group 40 - Data.csv"
	raw_data = pd.read_csv(path, header=0)

	# Drop empty entries
	dengvaxia_data = raw_data.drop("ID", axis=1)  # Drop early to help in dropping rows
	dengvaxia_data.dropna(how="all", inplace=True)

	# Drop unnecessary features
	dengvaxia_data.drop([
				"Timestamp",
				"Tweet URL",
				"Group",
				"Collector",
				"Category",
				"Topic",
				"Keywords",
				"Account handle",
				"Account name",
				"Account bio",
				"Location",
				"Tweet Translated",
				"Screenshot",
				"Quote Tweets",
				"Views",
				"Reasoning",
				"Remarks",
				"Add columns here",
				"Add columns here.1",
				"Add columns here.2",
				"Reviewer",
				"Review",
				], axis=1, inplace=True,)

	list(dengvaxia_data)	
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	['Account type',
	'Joined',
	'Following',
	'Followers',
	'Tweet',
	'Tweet Type',
	'Date posted',
	'Content type',
	'Likes',
	'Replies',
	'Retweets',
	'Rating']
</code>
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								We then checked for missing values in each of the columns. <br>
								The only one with missing data was the <b>Account type</b> column. This was fixed by simply
								filling the missing value with 'Anonymous'
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	# Prints out missing values
	for i in dengvaxia_data.columns:
	print("Number of missing data in", i + ":", dengvaxia_data[i].isnull().sum())

	# Fill missing Account Type entries with 'Anonymous'
	dengvaxia_data["Account type"].fillna("Anonymous", inplace=True)
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	<label style="color: red">Number of missing data in Account type: 1</label>
	Number of missing data in Joined: 0
	Number of missing data in Following: 0
	Number of missing data in Followers: 0
	Number of missing data in Tweet: 0
	Number of missing data in Tweet Type: 0
	Number of missing data in Date posted: 0
	Number of missing data in Content type: 0
	Number of missing data in Likes: 0
	Number of missing data in Replies: 0
	Number of missing data in Retweets: 0
	Number of missing data in Rating: 0
</code>
</pre>
							</section>
						</div>
						<div id="format-consistency" class="col-12">
							<section class="box style4 desc">
								<h3>Format Consistency</h3>
									We then performed <b>data validation</b> by ensuring that every entry in each column has the
									correct data type. <br>
									This involved converting all the date strings into <b>datetimes</b> and all the numerical counts
									into <b>integers</b>.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	# DF to store formatted data
	dengvaxia_formatted = dengvaxia_data.copy()

	# Convert dates to datetime
	dengvaxia_formatted["Joined"] = pd.to_datetime(dengvaxia_formatted["Joined"], format="%m/%y")
	dengvaxia_formatted["Date posted"] = pd.to_datetime(dengvaxia_formatted["Date posted"], format="%d/%m/%y %H:%M",
			errors="coerce").fillna(pd.to_datetime(dengvaxia_formatted["Date posted"], format="%d/%m/%Y %H:%M", errors="coerce"))
	
	# Convert floats to ints
	dengvaxia_formatted["Following"] = dengvaxia_formatted["Following"].astype(int)
	dengvaxia_formatted["Followers"] = dengvaxia_formatted["Followers"].astype(int)
	dengvaxia_formatted["Likes"] = dengvaxia_formatted["Likes"].astype(int)
	dengvaxia_formatted["Replies"] = dengvaxia_formatted["Replies"].astype(int)
	dengvaxia_formatted["Retweets"] = dengvaxia_formatted["Retweets"].astype(int)
	
	# Display changes
	changes = pd.DataFrame(
		{
			"Old datatype": dengvaxia_data.dtypes,
			"New datatype": dengvaxia_formatted.dtypes,
		}
	)
	changes.style.set_properties(**{"text-align": "left"})
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
								<img src="images/1_format_results.png" alt="" class="result"/>
							</section>
						</div>
						<div id="examine-distribution" class="col-12">
							<section class="box style4 desc">
								<h3>Handling Outliers: Examining the Distribution</h3>
								We decided to handle outliers for the columns <b>'Likes', 'Replies', 'Retweets', 'Following', 'Followers',
								and 'Date posted',</b> as outliers from these columns will most likely skew the dataset during the modeling phase. <br><br>

								Recall that we can detect outliers using <b>Z-scores</b> or <b>Interquartile Range (IQR)</b>. <br>
								Z-scores, however are only effective on normally distributed data while IQR works well for skewed data. 
								Hence, it is important to first visualize the distributions for the aforementioned columns.
								The code block below plots the data of each column to a <b>histogram</b>.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	import seaborn as sns
	import matplotlib.pyplot as plt
	
	sns.set_theme()
	
	# Displays histogram of a column
	def check_dist_col(column):
			plt.figure(figsize=(16, 5))
			plt.subplot(2, 1, 1)
			sns.histplot(dengvaxia_formatted[column], kde=True)
	
			plt.show()
	
	# Displays histogram of a column using their index
	def check_dist(i):
			plt.figure(figsize=(16, 5))
			plt.subplot(2, 3, i + 1)
			sns.histplot(dengvaxia_formatted[columns[i]], kde=True)
	
			plt.show()
	
	# Display histograms for the aforementioned columns
	columns = ["Likes", "Replies", "Retweets", "Following", "Followers", "Date posted"]
	for i in range(len(columns)):
			check_dist(i)
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
								<div class="grid-container">
									<img src="images/2a_likes_before.png" alt="" class="result"/>
									<img src="images/2b_replies_before.png" alt="" class="result"/>
									<img src="images/2c_retweets_before.png" alt="" class="result"/>
									<img src="images/2d_following_before.png" alt="" class="result"/>
									<img src="images/2e_followers_before.png" alt="" class="result"/>
									<img src="images/2f_datePosted_before.png" alt="" class="result"/>
								</div>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								Here we observe that <b>most of the columns are skewed to the left</b>, and not normally distributed.
								For this reason, we must perform <b>IQR</b> for detecting outliers. <br>
								Before that, however, there seems to be a blank histogram for the <b>'Followers'</b> column.
								Let's take a closer look using the describe() function.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	dengvaxia_formatted["Followers"].describe()
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	count    1.500000e+02
	<label style="color: black">mean     6.739463e+04</label>
	<label style="color: red">std      7.299880e+05</label>
	<label style="color: black">min      0.000000e+00</label>
	25%      2.307500e+02
	50%      9.985000e+02
	75%      3.543750e+03
	<label style="color: red">max      8.944169e+06</label>
	Name: Followers, dtype: float64
</code>
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								This means that for the 'Followers' column: <br>
								<ol>
									<li>The minimum value is 0 followers</li>
									<li>The maximum value is <label style="color: red">8944169 followers!</label></li>
									<li>A mean of 67394 but a <label style="color: red">standard devation of 729988!</label></li>
								</ol>
								The account with 8944169 followers <b>severely skewed the data</b> as the other values are relatively extremely small, 
								causing the histogram for 'Followers' column to be seemingly blank. The gap between the maximum value and the rest is extremely huge. <br>  <br>
								We will take a look at this again when we finally handle the outliers.
							</section>
						</div>
						<div id="detecting-outliers" class="col-12">
							<section class="box style4 desc">
								<h3>Handling Outliers: Detecting Outliers</h3>
									Recall that in box plots, any data point outside its whiskers, i.e. 1.5 times the interquartile range 
									above the upper quartile and below the lower quartile <b>(Q1 - 1.5 * IQR or Q3 + 1.5 * IQR)</b>, is an outlier. <br>

									For easier execution of detecting outliers for different categories, we create a function that takes in a column of the dataset as its parameter.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	import matplotlib.pyplot as plt
	import seaborn as sns
	import numpy as np
	import plotly.express as px
	
	def visualize_outlier(column):
			# Display boxplot
			sns.boxplot(dengvaxia_formatted, y=column, orient="v").set(xlabel=None, ylabel=column)
	
			# Find q1 and q3 values
			q1, q3 = np.percentile(sorted(dengvaxia_formatted[column]), [25, 75])
			print(f"Lower quartile (Q1): {q1}")
			print(f"Higher quartile (Q3): {q3}")
	
			# Compute IRQ
			iqr = q3 - q1
			print(f"IQR: {iqr}")
	
			# Find lower and upper bounds
			lower_bound = q1 - (1.5 * iqr)
			upper_bound = q3 + (1.5 * iqr)
	
			outliers = [x for x in dengvaxia_formatted[column] if x <= lower_bound or x >= upper_bound]
	
			# Display results
			print(f"Outliers: {outliers}")
			print(f"Number of outliers: {len(outliers)}")
			return outliers
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								<h3>Outliers for 'Likes'</h3>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	likes_outliers = visualize_outlier("Likes")
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	Lower quartile (Q1): 2.0
	Higher quartile (Q3): 22.75
	IQR: 20.75
	<label style="color: black">Outliers: [63, 365, 64, 54, 114, 65, 79, 95, 69, 228, 67, 88, 55, 71]</label>
	<label style="color: green">Number of outliers: 14</label>
</code>
</pre>
								<img src="images/3a_likes_outliers.png" alt="" class="result"/>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								There are <b><label style="color: green">14 outliers</label></b> in 'Likes', which are the tweets with 
								<b><label style="color: black">63, 365, 64, 54, 114, 65, 79, 95, 69, 228, 67, 88, 55, and 71 likes</label></b>. <br><br><br>

								<h3>Outliers for 'Replies'</h3>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	replies_outliers = visualize_outlier("Replies")
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	Lower quartile (Q1): 0.0
	Higher quartile (Q3): 2.0
	IQR: 2.0
	<label style="color: black">Outliers: [18, 5, 6, 6, 18, 15, 9, 12, 5, 6, 8, 5]</label>
	<label style="color: green">Number of outliers: 12</label>
</code>
</pre>
								<img src="images/3b_replies_outliers.png" alt="" class="result"/>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								There are <b><label style="color: green">12 outliers</label></b> in 'Replies', which are the tweets with 
								<b><label style="color: black">18, 5, 6, 6, 18, 15, 9, 12, 5, 6, 8, and 5 replies</label></b>. <br><br><br>

								<h3>And so on...</h3>
								The following is a compilation of the outliers detected from the columns <b>'Retweets', 'Following', and 'Followers'</b>.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	retweets_outliers = visualize_outlier("Retweets")
	following_outliers = visualize_outlier("Following")
	followers_outliers = visualize_outlier("Followers")
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	<b># IQR result for 'Retweets'</b>
	Lower quartile (Q1): 0.0
	Higher quartile (Q3): 8.75
	IQR: 8.75
	<label style="color: black">Outliers: [24, 118, 39, 38, 84, 31, 31, 42, 27, 50, 25, 31, 23, 29]</label>
	<label style="color: green">Number of outliers: 14</label>
</code>
</pre>
								<img src="images/3c_retweets_outliers.png" alt="" class="result"/>
<pre>
<code class="compact">	
	<b># IQR result for 'Following'</b>
	Lower quartile (Q1): 357.0
	Higher quartile (Q3): 1995.0
	IQR: 1638.0
	<label style="color: black">Outliers: [4998, 4703, 9380, 4874, 15211, 5895, 4995, 4980, 5895, 4572, 4871, 11780, 5655, 23135]</label>
	<label style="color: green">Number of outliers: 14</label>
</code>
</pre>
								<img src="images/3d_following_outliers.png" alt="" class="result"/>
<pre>
<code class="compact">	
	<b># IQR result for 'Followers'</b>
	Lower quartile (Q1): 230.75
	Higher quartile (Q3): 3543.75
	IQR: 3313.0
	<label style="color: black">Outliers: [128160, 21916, 21091, 10215, 10471, 72669, 13796, 30149, 65400, 70287, 21613, 161352, 13884, 28791, 8944169, 23248, 28790, 
		       60461, 13757, 118917, 8556, 28790, 23253, 25194]</label>
	<label style="color: green">Number of outliers: 24</label>
</code>
</pre>
								<img src="images/3e_followers_outliers.png" alt="" class="result"/>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								<h3>Outliers for 'Date posted'</h3>
								Since datetime formats cannot be easily visualized using box plots, we just manually calculate for the
								quartiles and the outliers <br>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	# Find q1 and q3 values
	q1, q3 = np.percentile(sorted(dengvaxia_formatted["Date posted"]), [25, 75])
	print(f"Lower quartile (Q1): {q1}")
	print(f"Higher quartile (Q3): {q3}")
	
	# Compute IRQ
	iqr = q3 - q1
	print(f"IQR: {iqr}")
	
	# Find lower and upper bounds
	lower_bound = q1 - (1.5 * iqr)
	upper_bound = q3 + (1.5 * iqr)
	
	date_outliers = [x for x in dengvaxia_formatted["Date posted"] if x <= lower_bound or x >= upper_bound]
	
	print(f"Outliers: {date_outliers}")
	print(f"Number of outliers: {len(date_outliers)}")
	
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	Lower quartile (Q1): 2018-09-23 14:01:00
	Higher quartile (Q3): 2021-06-12 18:30:30
	IQR: 993 days 04:29:30
	<label style="color: black">Outliers: []</label>
	<label style="color: green">Number of outliers: 0</label>
</code>
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style6 desc">
								There are <b>no outliers</b> for 'Date posted'. This means that we no longer need to handle outliers for this column.
							</section>
						</div>
						<div id="imputing-outliers" class="col-12">
							<section class="box style4 desc">
								<h3>Handling Outliers: Imputing the Outliers</h3>
									There are many ways to deal with outliers. In this project, since most of the columns are heavily skewed, 
									and there are outliers that have an immense gap from the rest of the data, we decided that the best way to deal
									with these outliers is by <b>imputing them with the median</b> of that column. This is because medians 
									are robust against, and are not easily affected by outliers. <br><br>

									With that, we now perform replacing the outliers for the aforementioned columns with the exception of 'Date posted'.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	# Impute outliers for 'Likes'
	for outlier in likes_outliers:
		dengvaxia_formatted["Likes"] = dengvaxia_formatted["Likes"].replace(
				outlier, np.median(dengvaxia_formatted["Likes"]))
	
	# Impute outliers for 'Replies'
	for outlier in replies_outliers:
		dengvaxia_formatted["Replies"] = dengvaxia_formatted["Replies"].replace(
				outlier, np.median(dengvaxia_formatted["Replies"]))
	
	# Impute outliers for 'Followers'
	for outlier in retweets_outliers:
		dengvaxia_formatted["Retweets"] = dengvaxia_formatted["Retweets"].replace(
				outlier, np.median(dengvaxia_formatted["Retweets"]))

	# Impute outliers for 'Followers'
	for outlier in following_outliers:
		dengvaxia_formatted["Following"] = dengvaxia_formatted["Following"].replace(
				outlier, np.median(dengvaxia_formatted["Following"]))
	
	# Impute outliers for 'Followers'
	for outlier in followers_outliers:
		dengvaxia_formatted["Followers"] = dengvaxia_formatted["Followers"].replace(
				outlier, np.median(dengvaxia_formatted["Followers"]))
	
	# Display updated histograms
	columns = ["Likes", "Replies", "Retweets", "Following", "Followers"]
	for i in range(len(columns)):
		check_dist(i)
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
								<div class="grid-container">
									<img src="images/4a_likes_after.png" alt="" class="result"/>
									<img src="images/4b_replies_after.png" alt="" class="result"/>
									<img src="images/4c_retweets_after.png" alt="" class="result"/>
									<img src="images/4d_following_after.png" alt="" class="result"/>
									<img src="images/4e_followers_after.png" alt="" class="result"/>
								</div>
							</section>
						</div>
						<div id="normalization" class="col-12">
							<section class="box style4 desc">
								<h3>Normalization</h3>
									Now that outliers have been dealth with, normalizing the data for these columns will now result to a more feasible and justifiable model.<br>
									This was done using sklearn's <b>MinMaxScaler</b>.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	from sklearn.preprocessing import MinMaxScaler

	dengvaxia_scaled = dengvaxia_formatted.copy(deep=True)
	scaler = MinMaxScaler()
	
	# Normalizes column using the MinMaxScaler
	def normalize(column):
			dengvaxia_scaled[[column]] = scaler.fit_transform(dengvaxia_scaled[[column]])
	
	# Normalize all numerical columns
	numerical_columns = ["Likes", "Replies", "Retweets", "Following", "Followers"]
	for column in numerical_columns:
			normalize(column)
	
	# Display changes
	unscaled_columns = dengvaxia_formatted[numerical_columns]
	scaled_columns = dengvaxia_scaled[numerical_columns]
	print(unscaled_columns.head(10))
	print(scaled_columns.head(10))
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	<b># Before normalization</b>
	  Likes   Replies  Retweets  Following  Followers
	0    6.0        0.0          3.0         366.0         236.0
	1    7.0        0.0          0.0         236.0        1297.0
	2    4.0        1.0          0.0         793.0        2896.0
	3   25.0        1.0          3.0        2094.0          49.0
	4    6.0        1.0          0.0         589.0         209.0
	5   24.0        1.0          6.0        1996.0        2310.0
	6    8.0        1.0          1.0         920.0        3553.0
	7    0.0        0.0          0.0         178.0           7.0
	8    2.0        2.0          0.0         776.0        2135.0
	9    2.0        0.0          0.0        2321.0        1461.0
	<b># After normalization</b>
	   Likes         Replies   Retweets   Following   Followers
	0  0.113208     0.00  0.142857   0.099972   0.028260
	1  0.132075     0.00  0.000000   0.063669   0.155311
	2  0.075472     0.25  0.000000   0.219213   0.346785
	3  0.471698     0.25  0.142857   0.582519   0.005868
	4  0.113208     0.25  0.000000   0.162245   0.025027
	5  0.452830     0.25  0.285714   0.555152   0.276614
	6  0.150943     0.25  0.047619   0.254677   0.425458
	7  0.000000     0.00  0.000000   0.047473   0.000838
	8  0.037736     0.50  0.000000   0.214465   0.255658
	9  0.037736     0.00  0.000000   0.645909   0.174949
</code>
</pre>
							</section>
						</div>
						<div id="categorical-encoding" class="col-12">
							<section class="box style4 desc">
								<h3>Categorical Data Encoding</h3>
								To make categorical data usable in analysis, it must converted into integer values through encoding.<br> 
								<b>One hot encoding</b> is used since our categorical data are nominal.<br><br>
								
								For the column <b>'Tweet Type'</b> which can take on several different values at the same time, a manual encoding 
								was performed to separate each type in their own columns.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	import numpy as np

	# Using one-hot encoding to encode the Content type and Rating features
	dengvaxia_encoded = pd.get_dummies(dengvaxia_scaled, prefix=['content-type', 'rating'],
	        columns=['Content type', 'Rating'])
	
	# Encodes columns that can have multiple categories
	def encode_multicategory(df, column, category):
		return np.where(df[column].str.contains(category), 1, 0)
	
	# Manually encoding the Tweet Type feature
	dengvaxia_encoded['Tweet Type'] = dengvaxia_encoded['Tweet Type'].str.lower()
	dengvaxia_encoded['tweet-type_Text'] = encode_multicategory(dengvaxia_encoded, 'Tweet Type', 'text')
	dengvaxia_encoded['tweet-type_Image'] = encode_multicategory(dengvaxia_encoded, 'Tweet Type', 'image')
	dengvaxia_encoded['tweet-type_Video'] = encode_multicategory(dengvaxia_encoded, 'Tweet Type', 'video')
	dengvaxia_encoded['tweet-type_URL'] = encode_multicategory(dengvaxia_encoded, 'Tweet Type', 'url')
	dengvaxia_encoded['tweet-type_Reply'] = encode_multicategory(dengvaxia_encoded, 'Tweet Type', 'reply')
	dengvaxia_encoded.drop('Tweet Type', axis=1, inplace=True)
	
	# Display changes
	print(dengvaxia_scaled.columns)   # Columns before encoding
	print(dengvaxia_encoded.columns)  # Columns after encoding
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="compact">
	<b>## Legend:</b> 
	<label style="color: red">Red</label>: columns removed
	<label style="color: green">Green</label>: columns added
	<b># Before encoding</b>
	Index(['Account type', 'Joined', 'Following', 'Followers', 'Tweet',
		<label style="color: red">'Tweet Type'</label>, 'Date posted', <label style="color: red">'Content type'</label>, 'Likes', 'Replies',
		'Retweets', <label style="color: red">'Rating'</label>],
		dtype='object')
	<b># After encoding</b>
	Index(['Account type', 'Joined', 'Following', 'Followers', 'Tweet',
		'Date posted', 'Likes', 'Replies', 'Retweets', <label style="color: green">'content-type_Emotional',
			'content-type_Rational', 'rating_FALSE', 'rating_MISDIRECTION',
			'rating_MISLEADING', 'rating_NEED CONTEXT', 'tweet-type_Text',
			'tweet-type_Image', 'tweet-type_Video', 'tweet-type_URL',
			'tweet-type_Reply']</label>,
			dtype='object')

</code>
</pre>
							</section>
						</div>
						<div id="cleaning-setup" class="col-12">
							<section class="box style4 desc">
								<h3>NLP: Cleaning and Setup</h3>
								We start off by cleaning up the tweet contents.
								To help in standardizing the tokens for NLP, we opted to <b>translate all the tweets to English</b>. <br>
								Unnecessary data such as emojis, URLs, and @mentions are also removed in this step. <br><br>
								The <b>googletrans</b> package was used to translate the tweets.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	# Note: googletrans 3.1.0a0 is already installed
	from googletrans import Translator
	import re
	import string
	
	dengvaxia_nlp = dengvaxia_encoded.copy()
	tweets_raw = dengvaxia_nlp['Tweet'].tolist()
	
	# Remove mentions
	def removeMentions(text):
		return re.sub(r'@\S+', '', text)
			
	tweets_clean = [removeMentions(t) for t in tweets_raw]
	
	# Remove URLs
	def removeURLs(text):
		return re.sub(r'http\S+', '', text)
			
	tweets_clean = [removeURLs(t) for t in tweets_clean]
	
	# Remove emojis
	url_emoji = "https://drive.google.com/uc?id=1G1vIkkbqPBYPKHcQ8qy0G2zkoab2Qv4v"
	df_emoji = pd.read_pickle(url_emoji)
	df_emoji = {v: k for k, v in df_emoji.items()}
	
	def removeEmojis(text):
		for emot in df_emoji:
			text = re.sub(r'('+emot+')', "", text)
		return text
	
	tweets_clean = [removeEmojis(t) for t in tweets_clean]
	
	# Remove emoticons
	url_emote = "https://drive.google.com/uc?id=1HDpafp97gCl9xZTQWMgP2kKK_NuhENlE"
	df_emote = pd.read_pickle(url_emote)
	
	def removeEmoticons(text):
		for emot in df_emote:
			text = re.sub(u'('+emot+')', "", text)
			text = text.replace("<3", "" ) # not included in emoticons database
		return text
	
	tweets_clean = [removeEmoticons(t) for t in tweets_clean]
	
	# Translate tweets to english
	translator = Translator()
	tweets_en = [t.text for t in translator.translate(tweets_clean, src='tl', dest='en')]
	dengvaxia_nlp['Tweet'] = tweets_en
	
	# Display results
	changes = pd.DataFrame({'Raw Tweet': tweets_raw, 'Cleaned Tweet': tweets_en})
	changes.style.set_properties(**{"text-align": "left", "max-width": "400px", "white-space": "normal"})
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
								<img src="images/5a_nlp_1.png" alt="" class="result"/>
							</section>
						</div>
						<div id="token-stopwords" class="col-12">
							<section class="box style4 desc">
								<h3>NLP: Tokenization and Stopwords</h3>
								<b>Tokenization</b> is done to separate the tweets into smaller pieces called tokens. Here, we chose tokens to be words. <br>
								Additionally, <b>stop words are removed</b> since they carry little to no information during analysis.<br><br>
								The nltk package's <b>stopwords and word_tokenize</b> functions were used to facilitate this.

							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	# Data for removing stop words and punctuations
	from nltk.downloader import download
	
	download("punkt")
	download("stopwords")
	
	from nltk.corpus import stopwords
	from nltk.tokenize import word_tokenize
	
	tweets = dengvaxia_nlp["Tweet"].tolist()
	
	# Convert to lowercase
	tweets = [t.lower() for t in tweets]
	
	# Remove punctuation
	tweets = [t.translate(str.maketrans("", "", string.punctuation)) for t in tweets]
	
	tweets_tokenized = []
	for tweet in tweets:
		# Tokenize the text into words
		words = word_tokenize(tweet)

		# Remove stopwords
		filtered_words = [
				word for word in words if word.lower() not in stopwords.words("english")
		]

		# Convert back into sentence
		filtered_sentence = " ".join(filtered_words)
		tweets_tokenized.append(filtered_sentence)
	dengvaxia_nlp["Tweet"] = tweets_tokenized
	
	# Display results
	changes = pd.DataFrame({"Tweet": tweets_en, "Tokens": [t.split() for t in tweets_tokenized]})
	changes.style.set_properties(**{"text-align": "left", "max-width": "400px", "white-space": "normal"})
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
								<img src="images/5b_nlp_2.png" alt="" class="result"/>
							</section>
						</div>
						<div id="lemmatization" class="col-12">
							<section class="box style4 desc">
								<h3>NLP: Lemmatization</h3>
								Since stemming gets rid of a lot of information which results in inaccurate root words, 
								we decided to perform the more costly but more accurate <b>lemmatization</b>. <br><br>
								The nltk package's <b>WordNetLemmatizer</b> was used to facilitate this.
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
<pre>
<code class="language-python">
	from nltk.stem import WordNetLemmatizer

	download("wordnet")
	download("omw-1.4")
	
	# Initialize the Lemmatizer
	lemmatizer = WordNetLemmatizer()
	tweets = dengvaxia_nlp["Tweet"].tolist()
	
	tweets_lemmatized = []
	for tweet in tweets:
			words = tweet.split()
	
			# Lemmatize each word
			lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
	
			# Convert back into sentence
			lemmatized_sentence = " ".join(lemmatized_words)
			tweets_lemmatized.append(lemmatized_sentence)
	dengvaxia_nlp["Tweet"] = tweets_lemmatized
	
	# Display results
	changes = pd.DataFrame(
			{"Tokens": tweets, "Lemmatized": [t.split() for t in tweets_lemmatized]}
	)
	changes.style.set_properties(**{"text-align": "left", "max-width": "400px", "white-space": "normal"})
</code> 
</pre>
							</section>
						</div>
						<div class="col-12">
							<section class="box style5">
								<img src="images/5c_nlp_3.png" alt="" class="result"/>
							</section>
						</div>
						<div class="col-12">
							<section class="box style4 desc">
								<h3>Preprocessing finished</h3>
								With that, the entire <b>Data Preprocessing </b>phase is complete. 
								What follows next is the <b><a href="visualization.html" class="colorless">Data Visualization</a></b>.
							</section>
						</div>
					</div>
				</div>
			</article>

		<!-- Team -->
			<article id="team" class="wrapper style4">
				<div class="container medium">
					<header>
						<h2>We'd like to hear from you.</h2>
						<p>You can add more information about the team members here.</p>
					</header>
					<div class="row">
						<div class="col-12">
							<form method="post" action="#">
								<div class="row">
									<div class="col-6 col-12-small">
										<input type="text" name="name" id="name" placeholder="Name" />
									</div>
									<div class="col-6 col-12-small">
										<input type="text" name="email" id="email" placeholder="Email" />
									</div>
									<div class="col-12">
										<input type="text" name="subject" id="subject" placeholder="Subject" />
									</div>
									<div class="col-12">
										<textarea name="message" id="message" placeholder="Message"></textarea>
									</div>
									<div class="col-12">
										<ul class="actions">
											<li><input type="submit" value="Send Message" /></li>
											<li><input type="reset" value="Clear Form" class="alt" /></li>
										</ul>
									</div>
								</div>
							</form>
						</div>
						<div class="col-12">
							<hr />
							<h3>Find me on ...</h3>
							<ul class="social">
								<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
								<li><a href="#" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
								<li><a href="#" class="icon brands fa-tumblr"><span class="label">Tumblr</span></a></li>
								<li><a href="#" class="icon brands fa-google-plus"><span class="label">Google+</span></a></li>
								<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
								<!--
								<li><a href="#" class="icon solid fa-rss"><span>RSS</span></a></li>
								<li><a href="#" class="icon brands fa-instagram"><span>Instagram</span></a></li>
								<li><a href="#" class="icon brands fa-foursquare"><span>Foursquare</span></a></li>
								<li><a href="#" class="icon brands fa-skype"><span>Skype</span></a></li>
								<li><a href="#" class="icon brands fa-soundcloud"><span>Soundcloud</span></a></li>
								<li><a href="#" class="icon brands fa-youtube"><span>YouTube</span></a></li>
								<li><a href="#" class="icon brands fa-blogger"><span>Blogger</span></a></li>
								<li><a href="#" class="icon brands fa-flickr"><span>Flickr</span></a></li>
								<li><a href="#" class="icon brands fa-vimeo"><span>Vimeo</span></a></li>
								-->
							</ul>
							<hr />
						</div>
					</div>
					<footer>
						<ul id="copyright">
							<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>
				</div>
			</article>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="assets/js/prism.js"></script>
	</body>
</html>
